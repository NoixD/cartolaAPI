{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88228, 122)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/calculated_features_final19356_253493_147567893553946290238604574175400014296.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scout_id', 'match_week', 'player_id', 'team_id', 'delta_price', 'position_id', 'year', 'name', 'has_played', 'score', 'average_points_last_1_rounds', 'average_price_last_1_rounds', 'team_points_last_1_rounds', 'team_goals_scored_last_1_rounds', 'team_goals_taken_last_1_rounds', 'enemy_goals_scored_last_1_rounds', 'enemy_goals_taken_last_1_rounds', 'enemy_points_last_1_rounds', 'home_team', 'team_goals_taken_last_1_rounds.1', 'average_plays_last_1_rounds_rb_play', 'average_plays_last_1_rounds_fc_play', 'average_plays_last_1_rounds_gc_play', 'average_plays_last_1_rounds_ca_play', 'average_plays_last_1_rounds_cv_play', 'average_plays_last_1_rounds_sg_play', 'average_plays_last_1_rounds_dd_play', 'average_plays_last_1_rounds_dp_play', 'average_plays_last_1_rounds_gs_play', 'average_plays_last_1_rounds_fs_play', 'average_plays_last_1_rounds_pe_play', 'average_plays_last_1_rounds_a_play', 'average_plays_last_1_rounds_ft_play', 'average_plays_last_1_rounds_fd_play', 'average_plays_last_1_rounds_ff_play', 'average_plays_last_1_rounds_g_play', 'average_plays_last_1_rounds_i_play', 'average_plays_last_1_rounds_pp_play', 'average_points_last_5_rounds', 'average_price_last_5_rounds', 'team_points_last_5_rounds', 'team_goals_scored_last_5_rounds', 'team_goals_taken_last_5_rounds', 'enemy_goals_scored_last_5_rounds', 'enemy_goals_taken_last_5_rounds', 'enemy_points_last_5_rounds', 'home_team.1', 'team_goals_taken_last_5_rounds.1', 'average_plays_last_5_rounds_rb_play', 'average_plays_last_5_rounds_fc_play', 'average_plays_last_5_rounds_gc_play', 'average_plays_last_5_rounds_ca_play', 'average_plays_last_5_rounds_cv_play', 'average_plays_last_5_rounds_sg_play', 'average_plays_last_5_rounds_dd_play', 'average_plays_last_5_rounds_dp_play', 'average_plays_last_5_rounds_gs_play', 'average_plays_last_5_rounds_fs_play', 'average_plays_last_5_rounds_pe_play', 'average_plays_last_5_rounds_a_play', 'average_plays_last_5_rounds_ft_play', 'average_plays_last_5_rounds_fd_play', 'average_plays_last_5_rounds_ff_play', 'average_plays_last_5_rounds_g_play', 'average_plays_last_5_rounds_i_play', 'average_plays_last_5_rounds_pp_play', 'average_points_last_10_rounds', 'average_price_last_10_rounds', 'team_points_last_10_rounds', 'team_goals_scored_last_10_rounds', 'team_goals_taken_last_10_rounds', 'enemy_goals_scored_last_10_rounds', 'enemy_goals_taken_last_10_rounds', 'enemy_points_last_10_rounds', 'home_team.2', 'team_goals_taken_last_10_rounds.1', 'average_plays_last_10_rounds_rb_play', 'average_plays_last_10_rounds_fc_play', 'average_plays_last_10_rounds_gc_play', 'average_plays_last_10_rounds_ca_play', 'average_plays_last_10_rounds_cv_play', 'average_plays_last_10_rounds_sg_play', 'average_plays_last_10_rounds_dd_play', 'average_plays_last_10_rounds_dp_play', 'average_plays_last_10_rounds_gs_play', 'average_plays_last_10_rounds_fs_play', 'average_plays_last_10_rounds_pe_play', 'average_plays_last_10_rounds_a_play', 'average_plays_last_10_rounds_ft_play', 'average_plays_last_10_rounds_fd_play', 'average_plays_last_10_rounds_ff_play', 'average_plays_last_10_rounds_g_play', 'average_plays_last_10_rounds_i_play', 'average_plays_last_10_rounds_pp_play', 'average_points_last_20_rounds', 'average_price_last_20_rounds', 'team_points_last_20_rounds', 'team_goals_scored_last_20_rounds', 'team_goals_taken_last_20_rounds', 'enemy_goals_scored_last_20_rounds', 'enemy_goals_taken_last_20_rounds', 'enemy_points_last_20_rounds', 'home_team.3', 'team_goals_taken_last_20_rounds.1', 'average_plays_last_20_rounds_rb_play', 'average_plays_last_20_rounds_fc_play', 'average_plays_last_20_rounds_gc_play', 'average_plays_last_20_rounds_ca_play', 'average_plays_last_20_rounds_cv_play', 'average_plays_last_20_rounds_sg_play', 'average_plays_last_20_rounds_dd_play', 'average_plays_last_20_rounds_dp_play', 'average_plays_last_20_rounds_gs_play', 'average_plays_last_20_rounds_fs_play', 'average_plays_last_20_rounds_pe_play', 'average_plays_last_20_rounds_a_play', 'average_plays_last_20_rounds_ft_play', 'average_plays_last_20_rounds_fd_play', 'average_plays_last_20_rounds_ff_play', 'average_plays_last_20_rounds_g_play', 'average_plays_last_20_rounds_i_play', 'average_plays_last_20_rounds_pp_play']\n",
      "RangeIndex(start=0, stop=88228, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary = ['scout_id','match_week','player_id', 'team_id', 'position_id', \n",
    "             'home_team.1', 'home_team.2', 'home_team.3', 'year', 'name', 'has_played',\n",
    "            'team_goals_taken_last_1_rounds.1', 'team_goals_taken_last_5_rounds.1',\n",
    "            'team_goals_taken_last_10_rounds.1', 'team_goals_taken_last_20_rounds.1']\n",
    "y = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noixd/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88228, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_home = df.loc[df.home_team == 1]\n",
    "df_away = df.loc[df.home_team == 0]\n",
    "df_away.home_team = -1\n",
    "df.fillna(0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0    43472\n",
      " 1.0    43364\n",
      "Name: home_team, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_home, df_away])\n",
    "print(df.home_team.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(795, 122)\n",
      "(86836, 122)\n"
     ]
    }
   ],
   "source": [
    "df_errado = df.loc[df.has_played == 0].loc[df.score != 0] ## Droping players that didnt play and had points\n",
    "print(df_errado.shape)\n",
    "print(df.shape)\n",
    "df = df.drop(df_errado.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37529, 122)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df.has_played ==1] ## Remove players that didnt play\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_points_last_1_rounds......................1774\n",
      "average_price_last_1_rounds.......................1774\n",
      "team_points_last_1_rounds.........................582\n",
      "team_goals_scored_last_1_rounds...................582\n",
      "team_goals_taken_last_1_rounds....................582\n",
      "enemy_goals_scored_last_1_rounds..................578\n",
      "enemy_goals_taken_last_1_rounds...................578\n",
      "enemy_points_last_1_rounds........................578\n",
      "average_plays_last_1_rounds_rb_play...............1774\n",
      "average_plays_last_1_rounds_fc_play...............1774\n",
      "average_plays_last_1_rounds_gc_play...............1774\n",
      "average_plays_last_1_rounds_ca_play...............1774\n",
      "average_plays_last_1_rounds_cv_play...............1774\n",
      "average_plays_last_1_rounds_sg_play...............1774\n",
      "average_plays_last_1_rounds_dd_play...............1774\n",
      "average_plays_last_1_rounds_dp_play...............1774\n",
      "average_plays_last_1_rounds_gs_play...............1774\n",
      "average_plays_last_1_rounds_fs_play...............1774\n",
      "average_plays_last_1_rounds_pe_play...............1774\n",
      "average_plays_last_1_rounds_a_play................1774\n",
      "average_plays_last_1_rounds_ft_play...............1774\n",
      "average_plays_last_1_rounds_fd_play...............1774\n",
      "average_plays_last_1_rounds_ff_play...............1774\n",
      "average_plays_last_1_rounds_g_play................1774\n",
      "average_plays_last_1_rounds_i_play................1774\n",
      "average_plays_last_1_rounds_pp_play...............1774\n",
      "average_points_last_5_rounds......................659\n",
      "average_price_last_5_rounds.......................659\n",
      "team_points_last_5_rounds.........................553\n",
      "team_goals_scored_last_5_rounds...................553\n",
      "team_goals_taken_last_5_rounds....................553\n",
      "enemy_goals_scored_last_5_rounds..................550\n",
      "enemy_goals_taken_last_5_rounds...................550\n",
      "enemy_points_last_5_rounds........................550\n",
      "average_plays_last_5_rounds_rb_play...............659\n",
      "average_plays_last_5_rounds_fc_play...............659\n",
      "average_plays_last_5_rounds_gc_play...............659\n",
      "average_plays_last_5_rounds_ca_play...............659\n",
      "average_plays_last_5_rounds_cv_play...............659\n",
      "average_plays_last_5_rounds_sg_play...............659\n",
      "average_plays_last_5_rounds_dd_play...............659\n",
      "average_plays_last_5_rounds_dp_play...............659\n",
      "average_plays_last_5_rounds_gs_play...............659\n",
      "average_plays_last_5_rounds_fs_play...............659\n",
      "average_plays_last_5_rounds_pe_play...............659\n",
      "average_plays_last_5_rounds_a_play................659\n",
      "average_plays_last_5_rounds_ft_play...............659\n",
      "average_plays_last_5_rounds_fd_play...............659\n",
      "average_plays_last_5_rounds_ff_play...............659\n",
      "average_plays_last_5_rounds_g_play................659\n",
      "average_plays_last_5_rounds_i_play................659\n",
      "average_plays_last_5_rounds_pp_play...............659\n",
      "average_points_last_10_rounds.....................574\n",
      "average_price_last_10_rounds......................574\n",
      "team_points_last_10_rounds........................553\n",
      "team_goals_scored_last_10_rounds..................553\n",
      "team_goals_taken_last_10_rounds...................553\n",
      "enemy_goals_scored_last_10_rounds.................550\n",
      "enemy_goals_taken_last_10_rounds..................550\n",
      "enemy_points_last_10_rounds.......................550\n",
      "average_plays_last_10_rounds_rb_play..............574\n",
      "average_plays_last_10_rounds_fc_play..............574\n",
      "average_plays_last_10_rounds_gc_play..............574\n",
      "average_plays_last_10_rounds_ca_play..............574\n",
      "average_plays_last_10_rounds_cv_play..............574\n",
      "average_plays_last_10_rounds_sg_play..............574\n",
      "average_plays_last_10_rounds_dd_play..............574\n",
      "average_plays_last_10_rounds_dp_play..............574\n",
      "average_plays_last_10_rounds_gs_play..............574\n",
      "average_plays_last_10_rounds_fs_play..............574\n",
      "average_plays_last_10_rounds_pe_play..............574\n",
      "average_plays_last_10_rounds_a_play...............574\n",
      "average_plays_last_10_rounds_ft_play..............574\n",
      "average_plays_last_10_rounds_fd_play..............574\n",
      "average_plays_last_10_rounds_ff_play..............574\n",
      "average_plays_last_10_rounds_g_play...............574\n",
      "average_plays_last_10_rounds_i_play...............574\n",
      "average_plays_last_10_rounds_pp_play..............574\n",
      "average_points_last_20_rounds.....................538\n",
      "average_price_last_20_rounds......................538\n",
      "team_points_last_20_rounds........................553\n",
      "team_goals_scored_last_20_rounds..................553\n",
      "team_goals_taken_last_20_rounds...................553\n",
      "enemy_goals_scored_last_20_rounds.................550\n",
      "enemy_goals_taken_last_20_rounds..................550\n",
      "enemy_points_last_20_rounds.......................550\n",
      "average_plays_last_20_rounds_rb_play..............538\n",
      "average_plays_last_20_rounds_fc_play..............538\n",
      "average_plays_last_20_rounds_gc_play..............538\n",
      "average_plays_last_20_rounds_ca_play..............538\n",
      "average_plays_last_20_rounds_cv_play..............538\n",
      "average_plays_last_20_rounds_sg_play..............538\n",
      "average_plays_last_20_rounds_dd_play..............538\n",
      "average_plays_last_20_rounds_dp_play..............538\n",
      "average_plays_last_20_rounds_gs_play..............538\n",
      "average_plays_last_20_rounds_fs_play..............538\n",
      "average_plays_last_20_rounds_pe_play..............538\n",
      "average_plays_last_20_rounds_a_play...............538\n",
      "average_plays_last_20_rounds_ft_play..............538\n",
      "average_plays_last_20_rounds_fd_play..............538\n",
      "average_plays_last_20_rounds_ff_play..............538\n",
      "average_plays_last_20_rounds_g_play...............538\n",
      "average_plays_last_20_rounds_i_play...............538\n",
      "average_plays_last_20_rounds_pp_play..............538\n"
     ]
    }
   ],
   "source": [
    "## TODO: tratar nulos\n",
    "for column in df.columns:\n",
    "    if column not in auxiliary:\n",
    "        if df[column].isnull().sum() > 0:\n",
    "            print('{0:.<50}{1}'.format(column, df[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average points by posicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_points = list()\n",
    "pos_list = ['Goleiro','Lateral', 'Zagueiro','Meia','Atacante', 'Tecnico']\n",
    "for pos in sorted(df.position_id.unique()):\n",
    "    avg_points.append(df.loc[df['position_id'] == pos].score.mean())\n",
    "\n",
    "print(\"Avg points per position: \", avg_points)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(avg_points, labels=pos_list, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most impactful stats by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pontuacao = [1.7, -0.5, -6.0, -2.0, -5.0, 5.0, 3.00, 7.00, -2.0,\n",
    "             0.5, -0.3, 5.0, 3.5, 1.0, 0.7, 8.0, -0.5, -3.5]\n",
    "abreviacao = ['RB', 'FC', 'GC', 'CA', 'CV', 'SG', 'DD', 'DP', 'GS',\n",
    "              'FS', 'PE', 'A', 'FT', 'FD', 'FF', 'G', 'I', 'PP']\n",
    "\n",
    "descricao = ['Robadas de Bola', 'Faltas Cometidas', 'Gol Contra', 'Cartao Amarelo',\n",
    "             'Cartao Vermelho', 'Jogo sem sofrer gol', 'Defesa Dificil', 'Defesa de Penalti',\n",
    "             'Gol Sofrido', 'Falta Sofrida', 'Passe Errado', 'Assistencia',\n",
    "             'Finalizacao na Trave', 'Finalizacao defendida', 'Finalizao pra Fora', 'Gol',\n",
    "             'Impedimento', 'Penalti Perdido']\n",
    "play_dict = {\n",
    "    'RB': 1.7,\n",
    "    'FC': -0.5,\n",
    "    'GC': -6.0,\n",
    "    'CA': -2.0,\n",
    "    'CV': -5.0,\n",
    "    'SG': 5.0,\n",
    "    'DD': 3.0,\n",
    "    'DP': 7.0,\n",
    "    'GS': -2.0,\n",
    "    'FS': 0.5,\n",
    "    'PE': -0.3,\n",
    "    'A': 5.0,\n",
    "    'FT': 3.5,\n",
    "    'FD': 1.0,\n",
    "    'FF': 0.7,\n",
    "    'G': 8.0,\n",
    "    'I': -0.5,\n",
    "    'PP': -3.5\n",
    "}\n",
    "\n",
    "description_dict = {\n",
    "    'RB': 'Robadas de Bola',\n",
    "    'FC': 'Faltas Cometidas',\n",
    "    'GC': 'Gol Contra',\n",
    "    'CA': 'Cartao Amarelo',\n",
    "    'CV': 'Cartao Vermelho',\n",
    "    'SG': 'Jogo sem sofrer gol',\n",
    "    'DD': 'Defesa Dificil',\n",
    "    'DP': 'Defesa de Penalti',\n",
    "    'GS': 'Gol Sofrido',\n",
    "    'FS': 'Falta Sofrida',\n",
    "    'PE': 'Passe Errado',\n",
    "    'A': 'Assistencia',\n",
    "    'FT': 'Finalizacao na Trave',\n",
    "    'FD': 'Finalizacao Defendida',\n",
    "    'FF': 'Finalizacao pra Fora',\n",
    "    'G': 'Gol',\n",
    "    'I': 'Impedimento',\n",
    "    'PP': 'Penalti Perdido'\n",
    "}\n",
    "\n",
    "\n",
    "for pos in sorted(df.position_id.unique()):\n",
    "    play_list = list()\n",
    "    for play in abreviacao:\n",
    "        play_list.append(play_dict[play] * df.loc[df['position_id'] == pos]['average_plays_last_1_rounds_' + play.lower() + '_play'].mean())\n",
    "    \n",
    "    print(play_list)\n",
    "    ind = np.arange(len(play_list))  # the x locations for the groups\n",
    "    width = 1       # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind, play_list, width=width, color='r')\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel('Average Points')\n",
    "    ax.set_title('Points per play for position %s' % (pos_list[pos - 1]))\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(abreviacao)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_points = list()\n",
    "\n",
    "\n",
    "team_dict = {\n",
    "'265':'BAH',\n",
    "'288':'CRI',\n",
    "'267':'VAS',\n",
    "'290':'GOI',\n",
    "'314':'AVA',\n",
    "'317':'JEC',\n",
    "'262':'FLA',\n",
    "'263':'BOT',\n",
    "'264':'COR',\n",
    "'266':'FLU',\n",
    "'275':'PAL',\n",
    "'276':'SAO',\n",
    "'277':'SAN',\n",
    "'282':'CAM',\n",
    "'283':'CRU',\n",
    "'284':'GRE',\n",
    "'285':'INT',\n",
    "'287':'VIT',\n",
    "'292':'SPT',\n",
    "'293':'CAP',\n",
    "'294':'CFC',\n",
    "'303':'PON',\n",
    "'315':'CHA',\n",
    "'316':'FIG',\n",
    "'327':'AME',\n",
    "'344':'SCZ',\n",
    "'373':'ATL-GO'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "'265':'b',\n",
    "'288':'y',\n",
    "'267':'k',\n",
    "'290':'g',\n",
    "'314':'b',\n",
    "'317':'g',\n",
    "'262':'r',\n",
    "'263':'k',\n",
    "'264':'k',\n",
    "'266':'r',\n",
    "'275':'g',\n",
    "'276':'r',\n",
    "'277':'k',\n",
    "'282':'k',\n",
    "'283':'b',\n",
    "'284':'b',\n",
    "'285':'r',\n",
    "'287':'r',\n",
    "'292':'r',\n",
    "'293':'r',\n",
    "'294':'g',\n",
    "'303':'k',\n",
    "'315':'g',\n",
    "'316':'k',\n",
    "'327':'g',\n",
    "'344':'r',\n",
    "'373':'r'\n",
    "}\n",
    "team_list = list()\n",
    "color_list = list()\n",
    "for team in sorted(df.team_id.unique()):\n",
    "    avg_points.append(df.loc[df.team_id == team].score.mean())\n",
    "    team_list.append(team_dict[str(team)])\n",
    "    color_list.append(color_dict[str(team)])\n",
    "    \n",
    "ind = np.arange(len(team_list))  # the x locations for the groups\n",
    "width = 1    # the width of the bars\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = plt.bar(ind, avg_points, color='g', width=1,align='center')\n",
    "for index,color in enumerate(color_list):\n",
    "    rects1[index].set_color(color)\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Average Points')\n",
    "ax.set_title('Team Average Points')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(team_list, rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average home points: \",df.loc[df.home_team == 1].score.mean())\n",
    "print(\"Average away points: \",df.loc[df.home_team == -1].score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Players per round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in (2014,2015,2016,2017):\n",
    "    print(\"Year: \" , year)\n",
    "    for rodada in sorted(df.match_week.unique()):\n",
    "        years = df.loc[df.year == year]\n",
    "        points = years.loc[years.match_week == rodada].sort_values(by='score', ascending=False)[0:19]\n",
    "        \n",
    "        print(\"Top 20 Player, Rodada: %s\" %(rodada))\n",
    "        print(points[['score','player_id', 'scout_id']])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noixd/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/noixd/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.position_id != 1] ## Removendo goleiros e tecnicos\n",
    "df = df.loc[df.position_id != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(auxiliary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32521, 107)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32521, 95)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeper_skills = ['dd', 'dp', 'gs'] ## removendo scouts de goleiro\n",
    "for col in list(df.columns):\n",
    "    for skill in keeper_skills:\n",
    "        if skill + '_play' in col:\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['delta_price'], axis=1, inplace=True) ## Seeing current info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'score'\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['score'], axis=1), df.score, test_size=0.2, random_state=42)\n",
    "# train = np.array(X_train).astype(float)\n",
    "\n",
    "# test = np.array(X_test).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Parameter Otimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', verbose_eval = True,early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    print(alg.get_xgb_params())\n",
    "    print('Fiting dataset')\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train,eval_metric='rmse', verbose=True)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    \n",
    "    print(\"Explained variance: \", metrics.explained_variance_score(y_train.values, dtrain_predictions))\n",
    "    print(\"Mean Absolute Error: \", metrics.mean_absolute_error(y_train.values, dtrain_predictions))\n",
    "    print(\"Mean Squared Error: \", metrics.mean_squared_error(y_train.values, dtrain_predictions))\n",
    "    print(\"Median Absolute Error: \", metrics.median_absolute_error(y_train.values, dtrain_predictions))\n",
    "    print(\"R2 Score: \", metrics.r2_score(y_train.values, dtrain_predictions))\n",
    "                    \n",
    "    plot_importance(alg)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing number of rounds\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, df.drop(['score'], axis=1), df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8b9fa9f4ccf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m  objective= 'reg:linear', scale_pos_weight=1, seed=27), \n\u001b[1;32m      8\u001b[0m  param_grid = param_test1, scoring='neg_mean_squared_error',iid=False, cv=5, verbose=5)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/cartolaAPI/env_cartola/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':(3,5,7,9),\n",
    " 'min_child_weight':(1,3,5,6)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=130, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'reg:linear', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='neg_mean_squared_error',iid=False, cv=5, verbose=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score.values)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing number of rounds\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, df.drop(['score'], axis=1), df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='rmse',iid=False, cv=5)\n",
    "gsearch1.fit(df.drop(['score'], axis=1), df.score)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=4,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.005,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.05\n",
    "params[\"min_child_weight\"] = 5\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.8\n",
    "params[\"scale_pos_weight\"] = 1.0\n",
    "#params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 7\n",
    "params[\"eval_metric\"] =\"rmse\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "plst = list(params.items())\n",
    "\n",
    "xgtrain = xgb.DMatrix(X_train, label=y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "\n",
    "num_rounds = 1000\n",
    "model = xgb.train(plst, xgtrain, num_rounds)\n",
    "print(\"Model train took : %s\" % time.time() - start_time)\n",
    "preds1 = model.predict(xgtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=7,\n",
    " min_child_weight=5,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " scale_pos_weight=1)\n",
    "xgb1.fit(X_train, y_train,eval_metric='rmse', verbose=True)\n",
    "print(\"Model Fit took : %s\" % time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.explained_variance_score(y_test.values, preds1))\n",
    "print(metrics.mean_absolute_error(y_test.values, preds1))\n",
    "print(metrics.mean_absolute_error(y_test.values, preds1))\n",
    "print(metrics.mean_squared_error(y_test.values, preds1))\n",
    "print(metrics.median_absolute_error(y_test.values, preds1))\n",
    "print(metrics.r2_score(y_test.values, preds1))\n",
    "\n",
    "print(preds1)\n",
    "print(y_test.values)\n",
    "# 0.931834118148\n",
    "# 0.674473175137\n",
    "# 0.674473175137\n",
    "# 1.13719610051\n",
    "# 0.409076118469\n",
    "# 0.931833478449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(model)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
